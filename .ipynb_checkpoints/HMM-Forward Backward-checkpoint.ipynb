{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* M 个隐状态 - $S^M$\n",
    "* 长度为T的观测序列 - $V^T$\n",
    "* 转移矩阵 - $A$\n",
    "* 发射矩阵 - $B$\n",
    "* 初始概率分布 - $\\pi$\n",
    "\n",
    "\n",
    "### Evaluation Problem\n",
    "\n",
    "给定 $\\theta, V_M \\to 估计 p(V_T|\\theta)$, 其中 $\\theta \\to s, v, a_{ij}, b_{jk}$\n",
    "\n",
    "方法：\n",
    "\n",
    "* 找出所有的隐状态，$S^M$， M是隐状态的数目\n",
    "* 从所有的隐状态序列$S^M$中，找到生成观测序列$V^T$的概率\n",
    "\n",
    "数学表达：\n",
    "\n",
    "$$p(V^T|\\theta) = \\sum_{r=1}^{R}p(V^T|S_{r}^{T})p(S_{r}^{T}) \\\\\n",
    "where \\quad S_{r}^{T} = \\{s_1(1), s_2(2)... s_r(T)\\}$$\n",
    "\n",
    "上面的R=最大数目的关于隐状态的可能序列\n",
    "因此可以得到，1-T的时间位置上，每个时刻t都可能是上述M个隐状态的任意一个取值，那么这个R的数目等于$R = M^T$\n",
    "\n",
    "\n",
    "为了计算序列长度为T的可观测序列$V^T$的生成概率， 我们应该采用每个可能的隐藏状态序列，计算它们产生$V^T$的概率，然后将这些概率相加。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以一个具体的示例讲解\n",
    "\n",
    "![image](imgs/Forward-and-Backward-Algorithm-in-Hidden-Markov-Model-adeveloperdiary.com_.jpg)\n",
    "\n",
    "上述通过隐状态生成的观测序列：$(sun, sun, rain) \\to (happy, sad, happy)$可以计算生成概率\n",
    "\n",
    "$$p(happy, sad, happy | sun, sun, rain ) = p(happy|sun) * p(sad|sun) * p(happy|rain)$$\n",
    "\n",
    "数学上：\n",
    "\n",
    "$$p(V^T|S_{r}^{T}) = \\prod_{t=1}^{T}p(v(t)|s(t))$$\n",
    "\n",
    "但是不幸的是，我们真的不知道隐藏状态的具体顺序，这些顺序会生成可观测变量$happy, sad, happy$\n",
    "\n",
    "我们可以计算$V^T$和与之对应的$S^T$的联合概率\n",
    "\n",
    "![image.png](imgs/Forward-and-Backward-Algorithm-in-Hidden-Markov-Model-adeveloperdiary.com-2.jpg)\n",
    "\n",
    "\n",
    "$$p(happy,sad,happy,sun,sun,rain) = p(sun|initial state) * p(sun|sun) * p(rain|sun) * p(happy|sun) * p(sad|sun) * p(happy|rain)$$\n",
    "\n",
    "$$p(S^T) = p(sun|initial state) * p(sun|sun) * p(rain|sun) = \\prod_{t=1}^{T}p(s(t)|s(t-1))$$\n",
    "$$p(V^T|S^T) = p(happy|sun) * p(sad|sun) * p(happy|rain) = \\prod_{t=1}^{T}p(v(t)|s(t))$$\n",
    "\n",
    "$$p(V^T, S^T) = p(V^T|S^T)p(S^T) = \\prod_{t=1}^{T}p(v(t)|s(t)) \\prod_{t=1}^{T}p(s(t)|s(t-1))$$\n",
    "\n",
    "上述只是特定的一个隐状态序列生成观测序列的例子，那么还有别的观测序列生成这个可观测序列，那么对所有的序列进行上述的计算然后求和\n",
    "\n",
    "假设只有两种隐状态sun, rain, 那么一共有三个时刻，所以隐状态序列的大小一共有$2^3=8$\n",
    "\n",
    "$$p(happy,sad,happy|model) = p(happy,sad,happy,sun,sun,sun) + p(happy,sad,happy,sun,sun,rain) + p(happy,sad,happy,sun,rain,rain)+ . . .$$\n",
    "\n",
    "数学上，假设共有R种可能的序列$R=M^T$\n",
    "\n",
    "$$\\begin{equation} \\label{eq1}\n",
    "\\begin{split}\n",
    "p(V^T|\\theta) & = \\sum_{All Seq of S}p(V^T, S^T) \\\\\n",
    "              & = \\sum_{All Seq of S}p(V^T|S^T)p(S^T) \\\\\n",
    "              & = \\sum_{r=1}^{R}\\prod_{t=1}^{T}p(v(t)|s(t)) \\prod_{t=1}^{T}p(s(t)|s(t-1)) \\\\\n",
    "              & = \\sum_{r=1}^{R}\\prod_{t=1}^{T}p(v(t)|s(t))p(s(t)|s(t-1))\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "但是计算复杂度很高，$O(M^T\\cdot T)$需要优化， 我们将采用动态规划来克服上述解决方案中的指数计算。 有两种这样的算法，Forward算法，backward算法,可以指数级复杂度降到多项式复杂度$O(M^2\\cdot T)$。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward算法\n",
    "\n",
    "给定一系列可见状态$V^T$，则隐马尔可夫模型在特定时间步长t处在特定隐藏状态s的概率是多少。\n",
    "\n",
    "$\\alpha(t) = p(v(1)...v(t), s(t)=j) = p(v_{1:t}, s(t)=j)$\n",
    "\n",
    "**当t=1时：**\n",
    "$$\\begin{equation} \\label{eq1}\n",
    "\\begin{split}\n",
    "\\alpha_{j}(1) & = p(v_{k}(1), s(1)=j) \\\\\n",
    "              & = p(v_{k}(1)|s(1)=j)p(s(1)=j) \\\\\n",
    "              & = \\pi_{j}p(v_{k}(1)|s(1)=j)\\\\\n",
    "              & = \\pi_{j}b_{jk}\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "- 其中$\\pi=初始状态分布$\n",
    "- 上式中的$b_{jk}$表示t=1时刻的发射概率\n",
    "\n",
    "如果通过向量的方式计算取不同的隐状态j，可以通过向量乘积计算，即$\\mathrm{\\alpha(1)} = \\mathrm{\\pi}\\mathrm{B_{:,k}}$\n",
    "\n",
    "**当t=2时：**\n",
    "\n",
    "获得t=1的结果后, t=2的计算公式中的一部分需要借助t=1的计算结果\n",
    "$$\\begin{equation} \\label{eq2}\n",
    "\\begin{split}\n",
    "\\alpha_{j}(2) & = p(v_{k}(1),v_{k}(2), s(2)=j) \\\\ \n",
    "              & = \\sum_{i=1}^{M} p(v_{k}(1), v_{k}(2), s(1)=i, s(2)=j) \\\\\n",
    "              & = \\sum_{i=1}^{M} p(v_{k}(2)|s(2)=j, v_{k}(1), s(1)=i)p(s(2)=j, v_{k}(1), s(1)=i) \\\\\n",
    "              & = \\sum_{i=1}^{M} p(v_{k}(2)|s(2)=j, v_{k}(1), s(1)=i)p(s(2)=j|s(1)=i, v_{k}(1))p(v_{k}(1), s(1)=i) \\\\\n",
    "              & = \\sum_{i=1}^{M} p(v_{k}(2)|s(2)=j)p(s(2)=j|s(1)=i)p(v_{k}(1), s(1)=i) \\\\\n",
    "              & = p(v_{k}(2)|s(2)=j)\\sum_{i=1}^{M} p(s(2)=j|s(1)=i)p(v_{k}(1), s(1)=i) \\\\\n",
    "              & = b_{jkv(2)}\\sum_{i=1}^{M} a_{i2}\\alpha_{i}(1)\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "如果通过向量的方式计算取不同的隐状态j，可以通过向量乘积计算，即$\\mathrm{\\alpha(2)} = \\mathrm{B_{:, k}} \\times (\\mathrm{\\alpha_{:,1}} \\cdot \\mathrm{a_{:, 2}})$\n",
    "\n",
    "* 其中 $a_{i2} = 转移概率$\n",
    "* $b_{jkv(2)} = 发射概率 在t=2时刻$\n",
    "* $\\alpha_{i}(1) = 前向概率在t=1时刻$\n",
    "\n",
    "解释： 因为在t=1时刻的，s(1)有M个状态，所以从s(1)到s(2)需要把M种状态都要考虑进来,在第二步的时候，加了sum符号\n",
    "\n",
    "\n",
    "进一步得到通用公式\n",
    "\n",
    "![image.png](imgs/generalized-Equation.jpg)\n",
    "\n",
    "\n",
    "当然也可以通过图示的方式\n",
    "\n",
    "![image.png](imgs/Forward-and-Backward-Algorithm-in-Hidden-Markov-Model-adeveloperdiary.com-4.jpg)\n",
    "\n",
    "上图如果用通用公式可以得到\n",
    "$$\\alpha_{2}(t) = b_{2k}\\sum_{i=1}^{M}\\alpha_{i}(t-1)a_{i2}$$\n",
    "如果把其他的也写出来\n",
    "$$\\alpha_{1}(t) = b_{1k}\\sum_{i=1}^{M}\\alpha_{i}(t-1)a_{i1}$$\n",
    "$$\\alpha_{3}(t) = b_{3k}\\sum_{i=1}^{M}\\alpha_{i}(t-1)a_{i3}$$\n",
    "\n",
    "\n",
    "总结：前向算法的递推关系如下\n",
    "\n",
    "![image.png](imgs/recursive-forward-equation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward算法代码实现\n",
    "\n",
    "假设做出如下定义：\n",
    "\n",
    "* 隐状态共两个,分别是AAA，BBB\n",
    "* 观测状态取值为三个，分别是0， 1， 2\n",
    "* 假设已经知道转移矩阵A，和发射矩阵B\n",
    "\n",
    "![image.png](imgs/init_matrix.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data/data_python.csv')\n",
    " \n",
    "V = data['Visible'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transition Probabilities\n",
    "A = np.array(((0.54, 0.46), (0.49, 0.51)))\n",
    " \n",
    "# Emission Probabilities\n",
    "B = np.array(((0.16, 0.26, 0.58), (0.25, 0.28, 0.47)))\n",
    " \n",
    "# Equal Probabilities for the initial distribution\n",
    "π = np.array((0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(V, A, B, π):\n",
    "    alpha = np.zeros((a.shape[0], V.shape[0]))\n",
    "    alpha[:, 0] = π*B[:, V[0]]\n",
    "    T = len(V)\n",
    "    M = A.shape[0]\n",
    "    for t in range(1, T):\n",
    "        for j in range(M):\n",
    "            alpha[j, t] = B[j, V[t]]*alpha[:, t-1]@A[:, j]\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = forward(V, A, B, π)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward算法\n",
    "\n",
    "\n",
    "$$\\begin{equation} \\label{eq2}\n",
    "\\begin{split}\n",
    "\\beta_{i}(t)  & = p(v_{k}(t+1),v_{k}(T)|s(t)=i) \\\\ \n",
    "              & = \\sum_{j=0}^{M} p(v_{k}(t+1)... v_{k}(T), s(t+1)=j|s(t)=i) \\\\\n",
    "              & = \\sum_{j=0}^{M} p(v_{k}(t+2)... v_{k}(T)|v_{k}(t+1), s(t+1)=j, s(t)=i)p(v_{k}(t+1),s(t+1)=j|s(t)=i)\\\\\n",
    "              & = \\sum_{j=0}^{M} p(v_{k}(t+2)... v_{k}(T)|v_{k}(t+1), s(t+1)=j, s(t)=i)p(v_{k}(t+1)|s(t+1)=j,s(t)=i)p(s(t+1)=j|s(t)=i)\\\\\n",
    "              & = \\sum_{j=0}^{M} p(v_{k}(t+2)... v_{k}(T)|s(t+1)=j)p(v_{k}(t+1)|s(t+1)=j)p(s(t+1)=j|s(t)=i)\\\\\n",
    "              & = \\sum_{j=0}^{M} \\beta_{j}(t+1)b_{jk}(t+1)a_{ij}\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "* 其中$a_{ij}$表示t时刻到t+1时刻的转移概率\n",
    "* $b_{jk}(t+1)$表示t+1时刻，单词为k的发射概率\n",
    "* $\\beta_{j}(t+1)$表示t+1时刻的后向概率\n",
    "\n",
    "当然也可以通过图示的方式\n",
    "\n",
    "![images.jpg](imgs/Forward-and-Backward-Algorithm-in-Hidden-Markov-Model-adeveloperdiary.com-5.jpg)\n",
    "\n",
    "![images.jpg](imgs/generialized-equation2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(V, A, B):\n",
    "    M = A.shape[0]\n",
    "    T = len(V)\n",
    "    beta = np.zeros((M, T))\n",
    "    \n",
    "    beta[:, -1] = np.ones(M)\n",
    "    \n",
    "    for t in range(T-2, 0, -1):\n",
    "        for j in range(M):\n",
    "            beta[j, t] = (B[:, V[t+1]]*beta[:, t+1])@A[j, :]\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = backward(V, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
