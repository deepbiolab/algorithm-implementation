{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF基础\n",
    "\n",
    "* CRF是无向图模型，通过对MEMM进行改进，不直接计算状态间的转移概率，而是计算最大团势函数的乘积所得的归一化后的分值，如果要计算概率需要除以partition function， 即Z，下图中的Y表示给定的序列如下所示\n",
    "\n",
    "$$$$\n",
    "\n",
    "$$P(Y)=\\frac{\\prod_{C}\\Psi_{C}(Y_C)}{Z} \\\\ Z = \\sum_{Y}\\prod_{C}\\Psi_{C}(Y_C) \\\\ \\Psi_{C}(Y_{C}) = exp(-E(Y_{C}))$$ \n",
    "\n",
    "\n",
    "* CRF是判别模型，且属于log-linear model, 即给定序列X，求对应的Y序列的概率，表示如下：\n",
    "\n",
    "$$P(y|x)=\\frac{exp\\sum_{k=1}^{K}w_k f_k(y, x)}{Z(x)} \\\\ Z(x)=\\sum_{y}exp\\sum_{k=1}^{K}w_k f_k(y, x)$$\n",
    "\n",
    "模型的参数化形式\n",
    "\n",
    "![image.png](img/img1.png)\n",
    "\n",
    "> - 其中转移状态函数：$t_{k}(y_{i-1}, y_{i}, x, i)$与状态特征函数：$s_{l}(y_{i}, x_{i}, i)$等价于$f(y, x)$\n",
    "> - 其中转移特征的权重$\\lambda_{k}$与状态特征的权重$\\mu_{l}$统一用$w$表示\n",
    "* CRF和HMM最大的不同就是条件随机场中同一特征(即$X$中的某一个$X_i$，注意X是一个序列) 在各个位置(即$Y$中的某一个$Y_i$)都有定义，可以对同一个特征在各个位置求和,将局部特征函数转化为一个全局特征函数.而HMM某一个时刻只和上一个时刻相关"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM+CRF模型\n",
    "\n",
    "#### 1.数据定义\n",
    "\n",
    "规定在数据集中有两类实体，人名和组织机构名称：\n",
    "\n",
    "- B-Person（人名的开始部分）\n",
    "- I-Person（人名的中间部分）\n",
    "- B-Organization（组织机构的开始部分）\n",
    "- I-Organization（组织机构的中间部分）\n",
    "- O（非实体信息）\n",
    "\n",
    "为方便起见，我们给每个类别一个索引，如下表所示：\n",
    "![img.png](img/tagindex.png)\n",
    "\n",
    "\n",
    "训练数据集是由各种句子组成，假设所有句子中单词可以构成词典word2ix，给定单词$w$,可以获得其索引$index_{w}$\n",
    "\n",
    "\n",
    "\n",
    "#### 2.BiLSTM-CRF 模型\n",
    "\n",
    "![img.png](img/model.png)\n",
    "\n",
    "- 模型输入：输入序列的单词索引\n",
    "- 模型输出：对应与输入序列的每个单词的标签索引\n",
    "- 模型组成：嵌入层>>>BiLSTM层>>>全连接层>>>CRF层\n",
    "\n",
    "\n",
    "#### 3. CRF层的作用\n",
    "\n",
    "假设不加入CRF层的话，选择BiLSTM层每一个时刻分数最高的类别作为预测结果。图中所示情况得到的结果为：w0是“I-Organization”，w1是“I-Person”，w2是“O”，w3是 “B-Organization” ，w4是 “O”。显然，这次的分类结果并不准确\n",
    "\n",
    "CRF层可以加入一些约束来保证最终预测结果是有效的。这些约束可以在训练数据时被CRF层自动学习得到。\n",
    "\n",
    "- 句子的开头应该是“B-”或“O”，而不是“I-”\n",
    "- “B-label1 I-label2 I-label3…”，在该模式中，类别1,2,3应该是同一种实体类别。\n",
    "- “O I-label”是错误的，命名实体的开头应该是“B-”而不是“I-”\n",
    "\n",
    "\n",
    "#### 4. BiLSTM-CRF 模型的损失函数\n",
    "\n",
    "CRF层中的损失函数包括两种类型的分数，而理解这两类分数的计算是理解CRF的关键。\n",
    "\n",
    "**4.1.Emission score**\n",
    "\n",
    "第一个类型的分数是发射分数（也成为状态分数）。这些状态分数来自BiLSTM层的输出。如上图黄色部分所示，w0被预测为B-Person的分数是1.5.\n",
    "\n",
    "定义 $X_{i, y_j}$ ，其中$i$是单词的位置索引，$y_j$是类别的索引\n",
    "\n",
    "注意：BiLSTM层的输出矩阵即发射矩阵，维度时n*k, 其中n=输入序列的长度，k=所有的标签数， $X_{i, :} \\ne 1$ 因为不是概率\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**4.2.Transition score**\n",
    "\n",
    "定义 $T_{y_i, y_j}$ 表示转移分数。例如，$t_{B−Person,I−Person}=0.9$表示从类别B−Person→I−Person的分数是0.9。因此，我们有一个所有类别间的转移分数矩阵。\n",
    "\n",
    "为了使转移分数矩阵更具鲁棒性，我们加上START 和 END两类标签。START代表一个句子的开始（不是句子的第一个单词），END代表一个句子的结束。下表是加上START和END标签的转移分数矩阵。\n",
    "\n",
    "要怎样得到这个转移矩阵呢？\n",
    "\n",
    "实际上，转移矩阵是BiLSTM-CRF模型的一个参数。在训练模型之前，你可以随机初始化转移矩阵的分数。这些分数将随着训练的迭代过程被更新，换句话说，CRF层可以自己学到这些约束条件。\n",
    "\n",
    "**4.3.损失函数定义**\n",
    "\n",
    "CRF损失函数由两部分组成，真实路径的分数 和 所有路径的总分数。真实路径的分数应该是所有路径中分数最高的。\n",
    "\n",
    "一个包含5个单词的句子，可能的类别序列如下：\n",
    "\n",
    "\n",
    "\n",
    "- 1. START B-Person B-Person B-Person B-Person B-Person END\n",
    "- 2. START B-Person I-Person B-Person B-Person B-Person END\n",
    "- …..\n",
    "- 10. START B-Person I-Person O B-Organization O END\n",
    "- N. O O O O O O O\n",
    "\n",
    "每种可能的路径的分数为Pi，共有N条路径，则路径的总分是\n",
    "\n",
    "$$P_{total} = P_1 + P_2 + ... + P_N = e^{S_1} + e^{S_2} + ... + e^{S_N} \\\\ e是常数e$$\n",
    "\n",
    "如果第十条路径是真实路径，也就是说第十条是正确预测结果，那么第十条路径的分数应该是所有可能路径里得分最高的。\n",
    "\n",
    "根据如下损失函数，在训练过程中，BiLSTM-CRF模型的参数值将随着训练过程的迭代不断更新，使得真实路径所占的比值越来越大。\n",
    "\n",
    "$$Loss Function = \\frac{P_{realpath}}{P_1 + P_2 + ... + P_N}$$\n",
    "\n",
    "进一步变换，将其变成对数损失函数：\n",
    "\n",
    "$$Loss Function = log(\\frac{P_{realpath}}{P_1 + P_2 + ... + P_N})$$\n",
    "\n",
    "由于我们的训练目标通常是最小化损失函数，所以我们加上负号：\n",
    "\n",
    "$$\\begin{equation} \\label{eq1}\n",
    "\\begin{split}\n",
    "Loss Function & = -log(\\frac{P_{realpath}}{P_1 + P_2 + ... + P_N}) \\\\\n",
    "              & = -log(\\frac{e^{S_{realpath}}}{e^{S_1} + e^{S_2} + ... + e^{S_N}}) \\\\\n",
    "              & = -(log(e^{S_{realpath}}) - log(e^{S_1} + e^{S_2} + ... + e^{S_N})) \\\\\n",
    "              & = -(S_{realpath} - log(e^{S_1} + e^{S_2} + ... + e^{S_N})) \\\\\n",
    "              & = -(\\sum_{i=1}^{N}X_{i, y_j} + \\sum_{i=1}^{N-1}T_{y_i, y_j} - log(e^{S_1} + e^{S_2} + ... + e^{S_N})) \\\\\n",
    "              & = -(S_{realpath} - S_{allpath})\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "$$where \\quad{S_{realpath}} = Emission Score_{realpath} + Transition Score_{realpath} \\\\ S_{allpath} = log(e^{S_1} + e^{S_2} + ... + e^{S_N})  \\\\ Emission Score_{realpath} = \\sum_{i=1}^{N}X_{i, y_j}  \\\\ Transition Score_{realpath} = \\sum_{i=1}^{N-1}T_{y_i, y_j}$$\n",
    "\n",
    "\n",
    "\n",
    "更新后的loss function，有两部分组成：\n",
    "\n",
    "- 1.给定序列的真实的tag序列的分数：即$S_{realpath}$\n",
    "- 2.给定序列的所有可能的tag序列的分数：即$S_{allpath}$\n",
    "\n",
    "\n",
    "```python\n",
    "    # Compute loss function\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        \"\"\"\n",
    "        sentence: token index at each timestamp\n",
    "        tags: true label index at each timestamp\n",
    "        \"\"\"\n",
    "        # Emission Matrix: feats, size=n*k, where n = len(sentence), k = len(tagsize)\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Real path score\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "\n",
    "        # All path score\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        \n",
    "        # loss = - (S_realpath - S_allpath)\n",
    "        loss = - (gold_score - forward_score) \n",
    "        return loss\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**4.3.1 真实路径分数 $S_{realpath}$**\n",
    "\n",
    "求真实路径分数的时候需要用到两个矩阵：\n",
    "- Emission 矩阵： 即BiLSTM的输出矩阵\n",
    "- Transition 矩阵： 可以先初始化，然后该矩阵会作为CRF的参数进行学习\n",
    "\n",
    "\n",
    "以“START B-Person I-Person O B-Organization O END”这条真实路径来说：\n",
    "\n",
    "句子中有5个单词，w1,w2,w3,w4,w5, 加上START和END 在句子的开始位置和结束位置，记为，w0，w6\n",
    "\n",
    "$${S_i} = Emission Score + Transition Score$$\n",
    "\n",
    "$$Emission Score = \\sum_{i=1}^{N}X_{i, y_j} = X_{0, START} + X_{1, B-Person} + X_{2, I-Person} + X_{3, O} + X_{4, B_Organization} + X_{5, O} + X_{6, END}$$ \n",
    "\n",
    "$$Transition Score = \\sum_{i=1}^{N-1}T_{y_i, y_j} = T_{START, B-person} + T_{B-person, I-person} + T_{I-person, O} + T_{O, B-organization} + T_{B-organization, O} + T_{O, END}$$\n",
    "\n",
    "\n",
    "注意：设$X_{0, START}=X_{6, END} =0$\n",
    "\n",
    "```python\n",
    "    # compute real path score\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        \"\"\"gives the score of a provides tag sequence\n",
    "        # feats: emission matrix from bilstm output, size = n*k\n",
    "            # where n = len(sentence), k = len(tagsize)\n",
    "        # tags: true label index at each timestamp\n",
    "        \"\"\"\n",
    "\n",
    "        score = torch.zeros(1)\n",
    "\n",
    "        # Put START_TAG at tag sequence head, such as [START_TAG， tag1, tag2... tagN]\n",
    "        tags = torch.cat(\n",
    "            [torch.tensor([self.tag2ix[START_TAG]], dtype=torch.long), tags])\n",
    "\n",
    "        # Compute real path score : \n",
    "        # realpath score = each timestamp emission score + each timestamp transition score\n",
    "        for i, feat in enumerate(feats):\n",
    "            # transition score from i -> i+1: self.transitions[tags[i + 1], tags[i]]: \n",
    "            # emission score at i: feat[tags[i+1]], because START_TAG in tag sequence, index not i\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        \n",
    "        # Add value from last tag to END_TAG at score\n",
    "        score = score + self.transitions[self.tag2ix[END_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "**4.3.2 所有路径分数 $S_{allpath} = log(e^{S_1} + e^{S_2} + ... + e^{S_N})$**\n",
    "\n",
    "核心思想：整个过程是一个分数的积聚过程。利用动态规划，首先，$i=0$时刻所有路径的总分先被计算出来，然后，我们计算i=0时刻 --> i=1时刻的所有路径的得分，最后计算i=0时刻 --> i=1时刻 --> i=2时刻的所有路径的得分，也就是我们需要的结果。\n",
    "\n",
    "假设序列长度为L，\n",
    "- 原问题：计算从第0时刻到第L时刻的所有路径总分数\n",
    "- 子问题：计算从第0时刻到第i时刻的所有路径总分数\n",
    "\n",
    "$$log(e^{S_1} + e^{S_2} + ... + e^{S_i}) = log\\left(\\sum_{j\\in{AllTags}} exp(\\alpha_{i, j})\\right)$$\n",
    "\n",
    "$$ where \\, \\alpha_{i, j} = log\\left(\\sum_{j' \\in{AllTags}} exp(\\alpha_{i-1, j'} + T_{j', j} + X_{j, w_i})\\right)$$\n",
    "\n",
    "* $j'$表示上一时刻的tag取值\n",
    "* $j$表示当前时刻的tag取值\n",
    "* $alpha_{i-1, j'}$表示上一个时刻的所有路径分数\n",
    "* $T_{j', j}$ 表示从上一时刻的tag$j'$到当前时刻的tag$j$的转移分数，可以由transition matrix求得\n",
    "* $X_{j, w_i}$ 表示当前时刻的单词$w_i$到tag$j$的发射分数，可以由emission matrix求得\n",
    "\n",
    "也可以通过下图很好的理解， 如果要求解下图中**抵达i时刻，tag为j的所有路径分数**\n",
    "\n",
    "![forward.png](img/forward_alg.png)\n",
    "\n",
    "为了方便理解，此处定义一个函数log-sum-exp\n",
    "\n",
    "\n",
    "$$\\begin{equation} \\label{eq2}\n",
    "\\begin{split}\n",
    "\\alpha_{i, j} & = logSumExp(\\\\\n",
    "              & + \\alpha_{i-1, 1} + T_{1,j} + X_{j, w_{i}} \\\\\n",
    "              & + \\alpha_{i-1, 2} + T_{2,j} + X_{j, w_{i}} \\\\\n",
    "              & + \\alpha_{i-1, 3} + T_{3,j} + X_{j, w_{i}} \\\\\n",
    "              & + \\alpha_{i-1, 4} + T_{4,j} + X_{j, w_{i}} \\\\\n",
    "              & + \\alpha_{i-1, 5} + T_{5,j} + X_{j, w_{i}} \\\\\n",
    "              & + \\alpha_{i-1, 6} + T_{6,j} + X_{j, w_{i}} \\\\\n",
    "              & + \\alpha_{i-1, 7} + T_{7,j} + X_{j, w_{i}})\n",
    "\\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "那么对于i时刻的每一个j,都可以计算上面的公式(上面的公式可以通过矩阵的方式计算，详见代码)，就可以得到第i个时刻每一个tag下所有路径分数\n",
    "\n",
    "需要注意的两点：\n",
    "\n",
    "1. 对于i=0时，即第一个时刻，第一个时刻标签为START_TAG， 此时通过给定一个$初始化\\alpha$代表$\\alpha_{i-1, j'}$，该$初始化\\alpha$通过START_TAG定义\n",
    "2. 对于i=L时,即最后一个时刻，最后一个时刻标签为END_TAG，而END_TAG没有发射到具体的单词上，所有不存在X_{j, w_i}，只需要计算上一个时刻的路径分数和上一个tag到END_TAG的转移分数\n",
    "\n",
    "\n",
    "```python\n",
    "    # compute all path score\n",
    "    def _forward_alg(self, feats):\n",
    "        \n",
    "        # for example: tagset = {START_TAG, tag1, tag2, tag3, END_TAG}\n",
    "        # tensor([[-10000.,-10000.,-10000.,-10000.,-10000.]])\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "\n",
    "        # All path score at START_TAG\n",
    "        # tensor([[-10000.,-10000.,-10000.,0,-10000.]])\n",
    "        init_alphas[0][self.tag2ix[START_TAG]] = 0 \n",
    "\n",
    "        # initial alpha at timestamp START_TAG\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # feats: emission matrix from bilstm output, size = n*k\n",
    "        # where n = len(sentence), k = len(tagsize)\n",
    "        for feat in feats:\n",
    "            \n",
    "            # alphas_t: a array to store score on each tag j at time i\n",
    "            alphas_t = []\n",
    "            for next_tag in range(self.tagset_size):\n",
    "\n",
    "                # feat[next_tag]: get emission score at tag j\n",
    "                # tensor([3]) -> tensor([[3,3,3,3,3]])\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "\n",
    "                # transitions[next_tag]: get transition scores from j' to j\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "\n",
    "                # compute alpha_{i-1, j'} + T_{j', j} + X_{j, Wi}\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "\n",
    "                # compute log_sum_exp on each tag j at time i and append to alphas_t\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            \n",
    "            # get all path score at time i for each tag j\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "\n",
    "        # get all path score at last time i (tag=END_TAG) for each tag j\n",
    "        terminal_var = forward_var + self.transitions[self.tag2ix[END_TAG]]\n",
    "\n",
    "        # get final all path score using log_sum_exp\n",
    "        # alpha = S_{allpath}\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T19:50:06.977675Z",
     "start_time": "2021-03-06T19:50:06.943765Z"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.47px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
